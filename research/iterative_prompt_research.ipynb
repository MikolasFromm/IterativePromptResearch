{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Prompt Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources and their cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node and Leaf definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from itertools import compress\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name : str, predecessor : 'Node' = None, alternative_name : str = None):\n",
    "        self.name = name\n",
    "        self.predecessor = predecessor\n",
    "        self.alternative_name : str = alternative_name\n",
    "        self.children : List['Node'] = []\n",
    "        self.is_active : bool = True\n",
    "\n",
    "    def get_child(self, index : int):\n",
    "        if (index >= len(self.children)):\n",
    "            assert IndexError\n",
    "        return self.children[index]\n",
    "    \n",
    "    def add_children(self, children : List['Node']):\n",
    "        for child in children:\n",
    "            child.predecessor = self\n",
    "            self.children.append(child)\n",
    "\n",
    "    def number_of_children(self) -> int:\n",
    "        return len(self.children)\n",
    "    \n",
    "    def number_of_active_children(self) -> int:\n",
    "        return sum(1 for child in self.children if child.is_active)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name}, #children: {len(self.children)}\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "class Leaf(Node):\n",
    "    def __init__(self, name : str, predecessor : 'Node' = None, alternative_name : str = None):\n",
    "        super().__init__(name, predecessor, alternative_name)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name}\"\n",
    "    \n",
    "class CorrectPath:\n",
    "    def __init__(self, root : Node, query : str, child_sequences : List[List['int']]):\n",
    "        ## sequence must be given in reversed order, having the first move at the last position\n",
    "        self.root = root\n",
    "        self.current_node = root\n",
    "        self.query = query\n",
    "        self.child_sequences = child_sequences \n",
    "        self.__current_step = 0\n",
    "        self.__valid_sequences : List['bool'] = [True for _ in child_sequences]\n",
    "    \n",
    "    def is_next_move_correct(self, move_index : int) -> bool:\n",
    "        if (all(self.__current_step >= len(sequenece) for sequenece in compress(self.child_sequences, self.__valid_sequences))): return False\n",
    "        if (any(move_index == sequence[self.__current_step] and self.current_node.get_child(sequence[self.__current_step]).is_active for sequence in compress(self.child_sequences, self.__valid_sequences))): return True\n",
    "        else: return False\n",
    "        \n",
    "    def make_correct_step(self, move_index : int) -> Node | None:\n",
    "        self.__valid_sequences = [(self.__current_step < len(sequence) and sequence[self.__current_step] == move_index) for sequence in self.child_sequences]\n",
    "        if not any(self.__valid_sequences): return None\n",
    "        self.current_node = self.current_node.get_child(next(compress(self.child_sequences, self.__valid_sequences))[self.__current_step])\n",
    "        self.__current_step += 1\n",
    "        return self.current_node\n",
    "    \n",
    "    def get_any_correct_step_index(self) -> int | None:\n",
    "        if (self.is_at_the_end()): return None\n",
    "        self.__valid_sequences = [(self.__current_step < len(sequence)) for sequence in self.child_sequences]\n",
    "        if not any(self.__valid_sequences): return None\n",
    "        return next(compress(self.child_sequences, self.__valid_sequences))[self.__current_step]\n",
    "    \n",
    "    def is_at_the_end(self) -> bool:\n",
    "        return any(self.__current_step >= len(sequence) for sequence in compress(self.child_sequences, self.__valid_sequences))\n",
    "    \n",
    "    def shortest_path(self) -> int:\n",
    "        return min(len(sequence) for sequence in self.child_sequences)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_node = self.root\n",
    "        self.__current_step = 0\n",
    "        self.__valid_sequences = [True for _ in self.child_sequences]\n",
    "\n",
    "def create_test_sequence(root : Node, query : str, child_sequences_str : List['str']) -> 'CorrectPath':\n",
    "    child_sequences = [[int(x) for x in child_sequence_str.split()] for child_sequence_str in child_sequences_str]\n",
    "    return CorrectPath(root, query, child_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WorldBank - XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "worldbank_namespaces =  {\n",
    "        'nt': 'urn:eu.europa.ec.eurostat.navtree'\n",
    "    }\n",
    "\n",
    "def parse_worldbank_xml(path : str) -> Node:\n",
    "    \"\"\"Parses the xml tree from the given path and returns the root node.\"\"\"\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    dataset : Node = Node(\"WorldBank\")\n",
    "    dataset.add_children(get_node_children(root, dataset))\n",
    "    return dataset\n",
    "\n",
    "def get_node_children(root : ET.Element, predecessor_node : Node) -> List['Node']:\n",
    "    \"\"\"Parses the given root node and returns the corresponding DataSet object.\"\"\"\n",
    "    datasets = []\n",
    "    for branch in root.findall('nt:branch', worldbank_namespaces):\n",
    "        title = branch.find('nt:title/[@language=\"en\"]', worldbank_namespaces).text\n",
    "        branch_dataset = Node(title, predecessor_node)\n",
    "        for child in branch.findall('nt:children', worldbank_namespaces):\n",
    "            branch_dataset.children = get_node_children(child, branch_dataset)\n",
    "        datasets.append(branch_dataset)\n",
    "\n",
    "    for leaf in root.findall('nt:leaf', worldbank_namespaces):\n",
    "        title = leaf.find('nt:title/[@language=\"en\"]', worldbank_namespaces).text\n",
    "        datasets.append(Leaf(title, predecessor_node))\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorldBank, #children: 3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldbank : Node = None\n",
    "if (os.path.exists(\"worldbank.pkl\")):\n",
    "    worldbank = pickle.load(open(\"worldbank.pkl\", \"rb\"))\n",
    "else:\n",
    "    worldbank = parse_worldbank_xml(\"worldBank_content.xml\")\n",
    "    pickle.dump(worldbank, open(\"worldbank.pkl\", \"wb\"))\n",
    "\n",
    "worldbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WebPage - HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from bs4 import BeautifulSoup\n",
    "from copy import deepcopy\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "SLEEP_TIME = 5\n",
    "TIMEOUT = 10\n",
    "DEPTH = 6\n",
    "ATTEMPTS_COUNT = 3\n",
    "\n",
    "def parse_html_webpage(path : str) -> Node:\n",
    "    \"\"\"Parses the html webpage into a tree and returns the root node.\"\"\"\n",
    "    dataset = Node(\"MFF home page\", None, path)\n",
    "    dataset.add_children(get_html_children(dataset, DEPTH))\n",
    "    return dataset\n",
    "\n",
    "def get_html_children(predecessor_node : Node, remaining_depth : int, cache : Dict[tuple[str, int], Node] = {}) -> List['Node']:\n",
    "    \"\"\"Parses the given soup and returns the corresponding DataSet object.\"\"\"\n",
    "    \"\"\"If item found in the cachce, it will be returned from there. Key of the cache is the url and the remaining depth.\"\"\"\n",
    "    \"\"\"I can always cut the depth of the children to the required level, but I cannot expand the children if the depth is not enough.\"\"\"\n",
    "    child_webpages = []\n",
    "    if (remaining_depth <= 0): return child_webpages\n",
    "\n",
    "    attempt_count = 1\n",
    "    page : requests.Response = None\n",
    "    soup : BeautifulSoup = None\n",
    "    while (attempt_count <= ATTEMPTS_COUNT):\n",
    "        try:\n",
    "            time.sleep(SLEEP_TIME)\n",
    "            page = requests.get(predecessor_node.alternative_name, timeout=TIMEOUT)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt_count} failed. Error: {e}\")\n",
    "        finally:\n",
    "            attempt_count += 1\n",
    "    \n",
    "    if (page == None): return child_webpages\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        if ('href' in link.attrs and link.text.strip() != '' and not url_is_blacklisted(link.attrs['href'])):\n",
    "            url = url_get_absolute(link.attrs['href'], predecessor_node.alternative_name)\n",
    "            ## check if any key with same or higher depth_remaining is in the cache\n",
    "            key : tuple[str,int] = (url, next((x for x in range(remaining_depth-1, DEPTH, 1) if (url, x) in cache), None))\n",
    "            if (key[1] is not None): ## if anything found in the cache\n",
    "                branch_dataset = deepcopy(cache[key]) ## copy the cached item\n",
    "                cut_children_depth(branch_dataset, remaining_depth-1) ## cut the depth to the required level\n",
    "                branch_dataset.predecessor = predecessor_node ## set the predecessor\n",
    "                branch_dataset.alternative_name = url ## set the alternative name to its url\n",
    "            else:\n",
    "                title = re.sub('[\\\\n\\\\s]+',' ',link.text.strip())\n",
    "                branch_dataset = Node(title, predecessor_node, url) ## create new item\n",
    "                branch_dataset.add_children(get_html_children(branch_dataset, remaining_depth - 1, cache)) ## expand the children\n",
    "                ## remove all chached items with same url and lower depth\n",
    "                if (any(k[0] == url and k[1] < remaining_depth for k in cache.keys())):\n",
    "                    cache = {k:v for k,v in cache.items() if k[0] != url or k[1] > remaining_depth}\n",
    "                cache[(url, remaining_depth-1)] = branch_dataset\n",
    "            child_webpages.append(branch_dataset) ## add to the children response\n",
    "    return child_webpages\n",
    "\n",
    "def url_is_blacklisted(url : str, base_url : str | None = None) -> bool:\n",
    "    \"\"\"Checks if the url is blacklisted. Blacklist is very basic.\"\"\"\n",
    "    ## keep relatives\n",
    "    if (url.startswith('./') or (url != \"/\" and url.startswith('/'))):\n",
    "        return False\n",
    "    \n",
    "    ## filter out some basic stuff\n",
    "    if (url == \"/\" \n",
    "        or url.startswith('#') \n",
    "        or url.startswith('mailto:') \n",
    "        or url.startswith('javascript:')\n",
    "        or url.startswith('tel:')\n",
    "        or (base_url is not None and not url.startswith(base_url))):\n",
    "        return True\n",
    "\n",
    "    ## passed\n",
    "    return False\n",
    "\n",
    "def url_get_absolute(input : str, current_url : str | None) -> str:\n",
    "        \"\"\"Tries to merge the relative input url with the current url prefix to get the absolute url. \n",
    "        If no current url is provided, the input is returned.\"\"\"\n",
    "        result = \"\"\n",
    "        \n",
    "        if (current_url is None): return input\n",
    "        ## remove the query string from the url\n",
    "        if ('?' in current_url): current_url = current_url.split('?')[0]\n",
    "        ## remove any anchors from the url\n",
    "        if ('#' in input): input = input.split('#')[0]\n",
    "\n",
    "        ## try to cut as much from the current url as possible\n",
    "        if (input.startswith('/')): \n",
    "            current_split = [x for x in current_url.split('/') if x != '']\n",
    "            input_split = [x for x in input.split('/') if x != '']\n",
    "            for i in range(len(current_split)):\n",
    "                if (len(input_split) == 0): return current_url\n",
    "                if (current_split[i] == input_split[0]): input_split.pop(0)\n",
    "            input = '/'.join(input_split)\n",
    "\n",
    "            if (current_url.endswith('/')): result = current_url + input\n",
    "            else: result = current_url + '/' + input\n",
    "        ## just append the relative to the current\n",
    "        elif (input.startswith('./')): result = current_url + input.strip('./')\n",
    "        ## otherwise legit URL given\n",
    "        else: result = input\n",
    "        ## always add the trailing slash if not present\n",
    "        if (not result.endswith('/') and not \".\" in result.split('/')[-1]): ## only except if file is given\n",
    "            result += '/'\n",
    "\n",
    "        return result\n",
    "\n",
    "def cut_children_depth(node : Node, depth : int):\n",
    "    \"\"\"Cuts the tree depth to the given depth.\"\"\"\n",
    "    if (depth <= 0):\n",
    "        node.children = []\n",
    "        return\n",
    "    for child in node.children:\n",
    "        cut_children_depth(child, depth - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage : Node = None\n",
    "if (os.path.exists(\"webpage.pkl\")):\n",
    "    webpage = pickle.load(open(\"webpage.pkl\", \"rb\"))\n",
    "else:\n",
    "    webpage = parse_html_webpage(\"https://www.mff.cuni.cz/\")\n",
    "    pickle.dump(webpage, open(\"webpage.pkl\", \"wb\"))\n",
    "\n",
    "webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FileSystem - HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import deque\n",
    "\n",
    "def parse_html_file(path : str) -> Node:\n",
    "    \"\"\"Parses the html file into a tree and returns the root node.\"\"\"\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        return get_html_file_children(soup)\n",
    "    \n",
    "def get_html_file_children(soup : BeautifulSoup) -> Node:\n",
    "    stack = deque()\n",
    "    initial_node : Node = None\n",
    "    previous_node : Node = None\n",
    "    for link in soup.find_all('a'):\n",
    "        if ('href' in link.attrs and link.text.strip() != ''):\n",
    "            url : str = link.attrs['href']\n",
    "            dir : str = url[:url.rindex('/')]\n",
    "            file : str = url[url.rindex('/')+1:]\n",
    "            text : str = link.text.strip()\n",
    "\n",
    "            if (initial_node is None):\n",
    "                initial_node = Node(text, None, dir)\n",
    "                previous_node = initial_node\n",
    "                continue\n",
    "\n",
    "            if (file == \"\" and  dir.startswith(previous_node.alternative_name)): ## when the file is empty, it is a directory\n",
    "                current_node = Node(text, previous_node, dir)\n",
    "                previous_node.children.append(current_node)\n",
    "                stack.append(previous_node)\n",
    "                previous_node = current_node\n",
    "            elif (file != \"\" and dir.startswith(previous_node.alternative_name)): \n",
    "                previous_node.children.append(Leaf(file, previous_node, dir))\n",
    "            else:\n",
    "                while (len(stack) > 0 and not dir.startswith(previous_node.alternative_name)):\n",
    "                    previous_node = stack.pop()\n",
    "                if (file == \"\"): ## when the file is empty, it is a directory\n",
    "                    current_node = Node(text, previous_node, dir)\n",
    "                    previous_node.children.append(current_node)\n",
    "                    stack.append(previous_node)\n",
    "                    previous_node = current_node\n",
    "                elif (file != \"\" and dir.startswith(previous_node.alternative_name)): \n",
    "                    previous_node.children.append(Leaf(file, previous_node, dir))\n",
    "    return initial_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOCUMENTS, #children: 43"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesystem : Node = None\n",
    "if (os.path.exists(\"filesystem.pkl\")):\n",
    "    filesystem = pickle.load(open(\"filesystem.pkl\", \"rb\"))\n",
    "else:\n",
    "    filesystem = parse_html_file(\"filesystem_content.html\")\n",
    "    pickle.dump(filesystem, open(\"filesystem.pkl\", \"wb\"))\n",
    "\n",
    "filesystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Assistant - ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenAI_secret\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m API_KEY\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconsts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODEL\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[1;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from openAI_secret import API_KEY\n",
    "from consts import MODEL\n",
    "\n",
    "class OpenAIWrapper:\n",
    "    def __init__(self, keep_whole_context : bool, system_message : str):\n",
    "        self.client = OpenAI(api_key=API_KEY)\n",
    "        self.keep_whole_context = keep_whole_context\n",
    "        self.system_message = system_message\n",
    "        self.messages = [self.__create_system_message(self.system_message)]\n",
    "\n",
    "    def __create_user_message(self, content):\n",
    "        return {\"role\": \"user\", \"content\": content}\n",
    "    \n",
    "    def __create_system_message(self, content):\n",
    "        return {\"role\": \"system\", \"content\": content}\n",
    "    \n",
    "    def __create_assistant_message(self, content):\n",
    "        return {\"role\": \"assistant\", \"content\": content}\n",
    "    \n",
    "    def __add_message(self, content):\n",
    "        if (self.keep_whole_context):\n",
    "            self.messages.append(self.__create_user_message(content))\n",
    "        else:\n",
    "            self.messages = [\n",
    "                self.__create_system_message(self.system_message),\n",
    "                self.__create_user_message(content) \n",
    "            ]\n",
    "\n",
    "    def __get_response(self):\n",
    "        full_response = self.client.chat.completions.create(\n",
    "            model = MODEL,\n",
    "            messages=self.messages,\n",
    "            temperature=0,\n",
    "            timeout=30\n",
    "        )\n",
    "\n",
    "        response_content = full_response.choices[-1].message.content\n",
    "        self.messages.append(self.__create_assistant_message(response_content))\n",
    "        return response_content\n",
    "    \n",
    "    def get_response_to_prompt(self, prompt) -> str:\n",
    "        \"\"\"Gets the assistant response to the given prompt. Depeneding on the \\\"keep_whole_context\\\" setting, the whole context is kept or just the current prompt is given to the assistant.\"\"\"\n",
    "        self.__add_message(prompt)\n",
    "        response = self.__get_response()\n",
    "        for message in self.messages:\n",
    "            print(f\"{message['content']}\")\n",
    "        return response if response is not None else \"\"\n",
    "    \n",
    "    def get_additional_response(self, prompt) -> str:\n",
    "        \"\"\"Gets a response to the given prompt, but regardless of the \\\"keep_whole_context\\\" setting, the previous context is kept.\"\"\"\n",
    "        self.messages.append(self.__create_user_message(prompt))\n",
    "        for message in self.messages:\n",
    "            print(f\"{message['content']}\")\n",
    "        return self.__get_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from consts import *\n",
    "\n",
    "class AssistantWorker:\n",
    "    def __init__(self, stemmer : SnowballStemmer, look_ahead_depth : int = 1):\n",
    "        self.stemmer = stemmer\n",
    "        self.look_ahead_depth = look_ahead_depth\n",
    "        print(MODEL)\n",
    "        pass\n",
    "\n",
    "    def create_llm_query(self, initial_query : str, path_done : List['Node'], current_node : Node, mode : int) -> str:\n",
    "        \"\"\"Creates a query for the LLM model based on the current node.\"\"\"\n",
    "        next_moves = []\n",
    "        prompt = \"\"\n",
    "        steps_so_far = \" -> \".join([node.name for node in path_done])\n",
    "\n",
    "        match mode:\n",
    "            case WORKER_MODE.STEP_BY_STEP | WORKER_MODE.MATCH_AND_FILTER:\n",
    "                next_moves = [f\"\\t{i}: {child.name}\\n\" for i, child in enumerate([child for child in current_node.children if child.is_active])]\n",
    "                prompt = (\n",
    "                f\"query: {initial_query}\\n\"\n",
    "                f\"steps done: {steps_so_far}\\n\"\n",
    "                f\"next possible subsection names:\\n\"\n",
    "                f\"{''.join(next_moves)}\"\n",
    "                )\n",
    "            case WORKER_MODE.LOOK_AHEAD:\n",
    "                for i, child in enumerate([child for child in current_node.children if child.is_active]):\n",
    "                    next_moves.append(f\"{i}: {self.create_look_ahead_prompt(child, self.look_ahead_depth-1, self.look_ahead_depth-1)}\")\n",
    "                prompt = (\n",
    "                f\"query: {initial_query}\\n\"\n",
    "                f\"steps done: {steps_so_far}\\n\"\n",
    "                f\"next possible subsection names:\\n\"\n",
    "                f\"{''.join(next_moves)}\"\n",
    "                )\n",
    "            case WORKER_MODE.KEYWORD_GEN_AND_MATCH:\n",
    "                prompt = (\n",
    "                f\"query: {initial_query}\\n\"\n",
    "                f\"For the query above, please write {NUM_OF_KEYWORDS} keywords that might be relevant names of subsections to dive into in an upcoming search. Prefere single words. Use the language of the query!\\n\"\n",
    "                f\"Please separate the keywords with semicolon. Dont write anything else!\\n\"\n",
    "                )\n",
    "\n",
    "        return prompt\n",
    "    \n",
    "    def create_llm_nonint_message(self) -> str:\n",
    "        \"\"\"Creates a message for the user when the answer was not an integer.\"\"\"\n",
    "        response = f\"You must only return integer, for example 3. If you don't know the answer, return -1\"\n",
    "        return response\n",
    "    \n",
    "    def create_llm_wrong_answer_message(self) -> str:\n",
    "        \"\"\"Creates a message for the user when the answer was not correct.\"\"\"\n",
    "        response = f\"Your answer was not correct. Please try another one.\"\n",
    "        return response\n",
    "\n",
    "    def process_llm_child_pick_response(self, raw_response : str) -> int | None:\n",
    "        \"\"\"Returns the child index of the llm decision. -1 means the assistant thinks it is the end already, returns NONE if non-digit answer given.\"\"\"\n",
    "        response = raw_response.strip()\n",
    "\n",
    "        if (response == \"-1\"):\n",
    "            return -1\n",
    "        \n",
    "        if not response.isdigit():\n",
    "            return None\n",
    "        else:\n",
    "            try:\n",
    "                int_response = int(response)\n",
    "                return int_response\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "    def process_llm_keyword_gen_response(self, raw_response : str) -> List['str']:\n",
    "        return [self.stemmer.stem(x.strip().casefold()) for x in raw_response.split(\";\")]\n",
    "    \n",
    "    def create_look_ahead_prompt(self, child : Node, depth_total : int, depth_remaining : int):\n",
    "        tab = '\\t'\n",
    "        newline = '\\n'\n",
    "        prompt = f\"{''.join([tab for _ in range(depth_total - depth_remaining)])}- {child.name}{newline}\"\n",
    "        \n",
    "        if depth_remaining == 0:\n",
    "            return prompt\n",
    "        \n",
    "        for i, grandchild in enumerate(child.children):\n",
    "            prompt += f\"{self.create_look_ahead_prompt(grandchild, depth_total, depth_remaining - 1)}\"\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions of text executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "REPETITION_COUNT = 1\n",
    "\n",
    "class TestResult:\n",
    "    def __init__(self):\n",
    "        self.__steps_taken = 0\n",
    "        self.__wrong_moves = 0\n",
    "        self.__non_int_responses = 0\n",
    "        self.__assisted_answers = 0\n",
    "        self.sucess = False\n",
    "\n",
    "    def mark_wrong_move(self):\n",
    "        \"\"\"Adds a wrong move to the result. Also increases the steps taken by 1.\"\"\"\n",
    "        self.mark_correct_move()\n",
    "        self.__wrong_moves += 1\n",
    "\n",
    "    def mark_non_int_responses(self):\n",
    "        \"\"\"Adds a non-integer response to the result. Also increases the steps taken by 1.\"\"\"\n",
    "        self.mark_correct_move()\n",
    "        self.__non_int_responses += 1\n",
    "\n",
    "    def mark_correct_move(self):\n",
    "        \"\"\"Increases the steps taken by 1.\"\"\"\n",
    "        self.__steps_taken += 1\n",
    "\n",
    "    def mark_assisted_answer(self):\n",
    "        \"\"\"Adds an assisted answer to the result.\"\"\"\n",
    "        self.__assisted_answers += 1\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{'Passed' if self.sucess else 'Failed'}, steps: {self.__steps_taken}, wrong: {self.__wrong_moves}, non-int: {self.__non_int_responses}, assisted: {self.__assisted_answers}\"\n",
    "    \n",
    "    def __repr__(self) -> str: return self.__str__()\n",
    "\n",
    "class TestRunner:\n",
    "    def __init__(self, stemmer : SnowballStemmer):\n",
    "        self.stemmer = stemmer\n",
    "        \n",
    "    def execute(self, tests : List['CorrectPath'], openai : OpenAIWrapper, worker : AssistantWorker, mode : int) -> List['TestResult']:\n",
    "        results : List['TestResult'] = []\n",
    "        for _ in range(REPETITION_COUNT):\n",
    "            for i, test in enumerate(tests):\n",
    "                test.reset()\n",
    "                result = self.__run(test.current_node, test.query, worker, openai, test, mode)\n",
    "                results.append(result)\n",
    "                print(f\"Test {i}: {result}\")\n",
    "\n",
    "    def __run(self, root : Node, query : str, worker : AssistantWorker, openai : OpenAIWrapper, correct_path : CorrectPath, mode : int) -> TestResult:\n",
    "        path_done : List['Node'] = []\n",
    "        current_node = root\n",
    "        result : TestResult = TestResult()\n",
    "        keywords : List[str] = []\n",
    "        index_translation : Dict[int, int] = {}\n",
    "        work_mode = mode\n",
    "        if (mode == WORKER_MODE.KEYWORD_GEN_AND_MATCH):\n",
    "            keywords = worker.process_llm_keyword_gen_response(openai.get_response_to_prompt(worker.create_llm_query(query, path_done, current_node, mode)))\n",
    "        \n",
    "        while (True):\n",
    "            if (mode == WORKER_MODE.KEYWORD_GEN_AND_MATCH):\n",
    "                current_node, index_translation = self.__reduce_node(current_node, keywords)\n",
    "                correct_path.current_node = current_node\n",
    "                work_mode = WORKER_MODE.STEP_BY_STEP\n",
    "\n",
    "            if (current_node.number_of_active_children() == 0 and not correct_path.is_at_the_end() and mode == WORKER_MODE.KEYWORD_GEN_AND_MATCH):\n",
    "                result.mark_wrong_move()\n",
    "                result.mark_assisted_answer()\n",
    "                current_node = correct_path.make_correct_step(correct_path.get_any_correct_step_index())\n",
    "            else:\n",
    "                prompt = worker.create_llm_query(query, path_done, current_node, work_mode)\n",
    "                next_child_index = worker.process_llm_child_pick_response(openai.get_response_to_prompt(prompt))\n",
    "                if (next_child_index is None):\n",
    "                    result.mark_non_int_responses()\n",
    "                    additional_prompt = worker.create_llm_nonint_message()\n",
    "                    next_child_index = worker.process_llm_child_pick_response(openai.get_additional_response(additional_prompt))\n",
    "                    if (next_child_index is None):\n",
    "                        result.mark_non_int_responses()\n",
    "                        result.sucess = False\n",
    "                        break\n",
    "                    else:\n",
    "                        should_break, next_child_index = self.__process_valid_response(next_child_index, result, worker, openai, correct_path, path_done, current_node.number_of_active_children(), index_translation)\n",
    "                        if (should_break): break\n",
    "                else:\n",
    "                    should_break, next_child_index = self.__process_valid_response(next_child_index, result, worker, openai, correct_path, path_done, current_node.number_of_active_children(), index_translation)\n",
    "                    if (should_break): break\n",
    "\n",
    "                ## continue to the next node\n",
    "                print(f\"Next child index: {next_child_index}\")\n",
    "                current_node = correct_path.make_correct_step(next_child_index)\n",
    "\n",
    "            if (correct_path.is_at_the_end()):\n",
    "                result.sucess = True\n",
    "                break\n",
    "            else:\n",
    "                path_done.append(current_node)\n",
    "        return result\n",
    "    \n",
    "    def __process_valid_response(self, next_child_index : int, result : TestResult, worker : AssistantWorker, openai : OpenAIWrapper, correct_path : CorrectPath, path_done : List['Node'], max_num_of_entries : int, index_translations : Dict['int', 'int'] = {}) -> tuple[bool, int]:\n",
    "        index_translated : bool = False\n",
    "        if (index_translations != {} and next_child_index != -1 and next_child_index < correct_path.current_node.number_of_active_children()):\n",
    "            index_translated = True\n",
    "            next_child_index = index_translations[next_child_index]\n",
    "            \n",
    "        if (correct_path.is_at_the_end()): ## when already at the end\n",
    "            if (next_child_index == -1): ## if the assistant knows it is the end\n",
    "                result.mark_correct_move()\n",
    "                result.sucess = True\n",
    "                return (True, -1)\n",
    "            else: ## if the assistant doesn't know it is the end\n",
    "                result.mark_wrong_move()\n",
    "                result.sucess = False\n",
    "                return (True, -1)\n",
    "        else:\n",
    "            num_of_tries = 1\n",
    "            while (\n",
    "                (not index_translated and next_child_index >= correct_path.current_node.number_of_active_children()) \n",
    "                or (not correct_path.is_next_move_correct(next_child_index) and num_of_tries <= max_num_of_entries)\n",
    "                ):\n",
    "                index_translated = False\n",
    "                result.mark_wrong_move()\n",
    "                wrong_response_prompt = worker.create_llm_wrong_answer_message()\n",
    "                next_child_index = worker.process_llm_child_pick_response(openai.get_additional_response(wrong_response_prompt))\n",
    "                if (next_child_index is None):\n",
    "                    result.mark_non_int_responses()\n",
    "                    additional_prompt = worker.create_llm_nonint_message()\n",
    "                    next_child_index = worker.process_llm_child_pick_response(openai.get_additional_response(additional_prompt))\n",
    "                    if (next_child_index is None):\n",
    "                        result.mark_non_int_responses()\n",
    "                        result.mark_assisted_answer()\n",
    "                        return (False, correct_path.get_any_correct_step_index())\n",
    "                    else:\n",
    "                        if (index_translations != {} and next_child_index != -1 and next_child_index < correct_path.current_node.number_of_active_children()):\n",
    "                            index_translated = True\n",
    "                            next_child_index = index_translations[next_child_index]\n",
    "                else:\n",
    "                    if (index_translations != {} and next_child_index != -1 and next_child_index < correct_path.current_node.number_of_active_children()):\n",
    "                        index_translated = True\n",
    "                        next_child_index = index_translations[next_child_index]\n",
    "                num_of_tries += 1\n",
    "\n",
    "            if (correct_path.is_next_move_correct(next_child_index)):\n",
    "                result.mark_correct_move()\n",
    "                return (False, next_child_index)\n",
    "            else:\n",
    "                result.mark_wrong_move()\n",
    "                result.mark_assisted_answer()\n",
    "                return (False, correct_path.get_any_correct_step_index())\n",
    "            \n",
    "    def __reduce_node(self, node : Node, keywords : List['str']) -> tuple[Node, Dict['int', 'int']]:\n",
    "        \"\"\"Reduces the tree based on the given keywords.\"\"\"\n",
    "        ## make copy of the node\n",
    "        reduced_node = deepcopy(node)\n",
    "        translation = {}\n",
    "        reduced_index = 0\n",
    "        for i, child in enumerate(reduced_node.children):\n",
    "            if (self.__is_relevant(child, keywords)):\n",
    "                translation[reduced_index] = i\n",
    "                reduced_index += 1\n",
    "            else:\n",
    "                child.is_active = False\n",
    "        return reduced_node, translation\n",
    "\n",
    "    def __is_relevant(self, node : Node, keywords : List['str']) -> bool:\n",
    "        \"\"\"Checks if the given node is relevant based on the given keywords.\"\"\"\n",
    "        return any(keyword in self.stemmer.stem(node.name.strip().casefold()) for keyword in keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Worldbank - Step by step\n",
    "Every test contains a source, a user (human friendly) query to which should be the relevant database table found and a list of sequences of indexes (zero based) that lead to the correct table.\n",
    "\n",
    "The table of content of whole eurostat database was gathered at February 2024 and is saved locally.\n",
    "\n",
    "When deciding, whether the current path is of the assistant is correct, any matching correct sequence will satisfy. All other sequences that are not following the same path are removed at the first node with a mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldbank_tests = [\n",
    "    create_test_sequence(worldbank, \"What was the GDP growth rate for Czech Republic in 2019?\", [\n",
    "        \"0 1 0 0 0 0\"]),\n",
    "    create_test_sequence(worldbank, \"How many people lived in Germany in 2020?\", [\n",
    "        \"0 2 1 1 0\", \"0 2 1 1 1\", \"0 2 1 1 2\", \n",
    "        \"0 2 1 1 3\", \"0 2 1 1 4\", \"0 2 1 1 5\", \n",
    "        \"0 2 1 1 6\", \"0 2 1 1 7\", \"0 2 1 1 8\", \n",
    "        \"0 2 1 1 9\", \"0 2 1 1 10\", \"0 2 1 1 11\", \n",
    "        \"0 2 1 1 12\"]),\n",
    "    create_test_sequence(worldbank, \"What was the unemployment rate in Austria in 2015?\", [\n",
    "        \"0 2 7 0 0 2 0\", \"0 2 7 0 0 2 3\", \"0 2 7 0 0 2 5\", \"0 2 7 0 0 2 0\"]),\n",
    "    create_test_sequence(worldbank, \"What percentage of the population in Europe had access to clean water and sanitation facilities in 2010?\", [\n",
    "        \"1 3 5 0\"]),\n",
    "    create_test_sequence(worldbank, \"What was the government expenditure on healthcare in Poland in 2018?\", [\n",
    "        \"0 2 4 2 0 0 0\", \"0 2 4 2 0 1 0\"]),\n",
    "    create_test_sequence(worldbank, \"How much renewable energy was consumed as a percentage of total energy consumption in France in 2020?\", [\n",
    "        \"0 7 1 0 0 4 0\", \"0 7 1 0 0 4 8\"]),\n",
    "    create_test_sequence(worldbank, \"What was the green-house-gases emissions level for Spain in 2014?\", [\n",
    "        \"0 7 0 0 0 0\", \"0 7 0 0 0 1\", \"0 7 0 0 0 5\", \n",
    "        \"2 6 0 0\", \"2 6 0 1\", \"2 6 0 2\", \"2 6 0 4\"]),\n",
    "    create_test_sequence(worldbank, \"What was the inflation rate in Italy in 2018?\", [\n",
    "        \"0 1 4 0 1\", \"0 1 4 0 4\", \"0 1 4 0 5\"]),\n",
    "    create_test_sequence(worldbank, \"What was the total external debt of Czech Republic in 2021, and how does it compare to its GDP?\", [\n",
    "        \"0 1 1 0 1 0\", \"0 1 1 0 1 3 0\", \"0 1 1 0 1 3 1\", \n",
    "        \"0 1 1 0 1 3 2\", \"0 1 1 0 1 3 7\", \"0 1 1 0 1 3 8\", \n",
    "        \"0 1 1 0 1 3 9\"]),\n",
    "    create_test_sequence(worldbank, \"What was the ratio of female to male participation in the labor force in Romania in 2015?\", [\n",
    "        \"0 2 7 0 0 0 0\", \"0 2 7 0 0 1 0\", \"0 2 7 0 2 2 0\", \"0 2 7 0 2 2 1\", \"0 2 7 0 2 2 2\",\n",
    "        \"0 2 7 0 2 2 3\", \"0 2 7 0 2 2 4\", \"0 2 7 0 2 2 5\", \"0 2 7 0 2 2 6\", \"0 2 7 0 2 2 7\",\n",
    "        \"0 2 7 0 2 2 8\", \"0 2 7 0 2 2 9\", \"0 2 7 0 2 2 10\", \"0 2 7 0 2 2 11\", \"0 2 7 0 2 2 12\",\n",
    "        \"0 2 7 0 2 2 16\", \"0 2 7 0 2 2 17\", \"0 2 7 0 2 2 18\", \"0 2 7 0 2 2 22\", \"0 2 7 0 2 2 23\",\n",
    "        \"0 2 7 0 2 3 0\", \"0 2 7 0 2 3 1\", \"0 2 7 0 2 3 2\", \"0 2 7 0 2 3 3\", \"0 2 7 0 2 3 4\", \"0 2 7 0 2 3 5\",\n",
    "        \"0 2 7 0 2 5 0\", \"0 2 7 0 2 5 1\", \"0 2 7 0 2 5 2\", \"0 2 7 0 2 5 3\", \"0 2 7 0 2 5 5\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Worldbank - keyword generation\n",
    "To reduce API costs, the assistant is asked to generate _N_ keywords that might be contained in the subsection name or in the table name. After the words are gathered, the tree is filtered so that only those nodes with name containing one of the following keywords is kept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# system_message = \"You are an assistant that is helping a user to navigate through the World Bank data.\\\n",
    "#     You are given a query and all available subsections.\\\n",
    "#     You should help the user to navigate to the correct subsection.\\\n",
    "#     Answer only with the number of the subsection.\\\n",
    "#     If you don't know the answer, return -1.\"\n",
    "# stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "# openai = OpenAIWrapper(False, system_message)\n",
    "# worker = AssistantWorker(stemmer, look_ahead_depth=1)\n",
    "# runner = TestRunner(stemmer)\n",
    "# runner.execute(worldbank_tests, openai, worker, WORKER_MODE.KEYWORD_GEN_AND_MATCH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
