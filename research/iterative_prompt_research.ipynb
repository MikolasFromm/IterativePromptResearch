{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Prompt Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources and their cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node and Leaf definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name : str, predecessor : 'Node' = None, alternative_name : str = None):\n",
    "        self.name = name\n",
    "        self.predecessor = predecessor\n",
    "        self.alternative_name : str = alternative_name\n",
    "        self.children = []\n",
    "\n",
    "    def get_child(self, index : int):\n",
    "        if (index >= len(self.children)):\n",
    "            assert IndexError\n",
    "        return self.children[index]\n",
    "    \n",
    "    def add_children(self, children : List['Node']):\n",
    "        for child in children:\n",
    "            child.predecessor = self\n",
    "            self.children.append(child)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name}, #children: {len(self.children)}\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "class Leaf(Node):\n",
    "    def __init__(self, name : str, predecessor : 'Node' = None, alternative_name : str = None):\n",
    "        super().__init__(name, predecessor, alternative_name)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WorldBank - XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "worldbank_namespaces =  {\n",
    "        'nt': 'urn:eu.europa.ec.eurostat.navtree'\n",
    "    }\n",
    "\n",
    "def parse_worldbank_xml(path : str) -> Node:\n",
    "    \"\"\"Parses the xml tree from the given path and returns the root node.\"\"\"\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    dataset : Node = Node(\"WorldBank\")\n",
    "    dataset.add_children(get_node_children(root, dataset))\n",
    "    return dataset\n",
    "\n",
    "def get_node_children(root : ET.Element, predecessor_node : Node) -> List['Node']:\n",
    "    \"\"\"Parses the given root node and returns the corresponding DataSet object.\"\"\"\n",
    "    datasets = []\n",
    "    for branch in root.findall('nt:branch', worldbank_namespaces):\n",
    "        title = branch.find('nt:title/[@language=\"en\"]', worldbank_namespaces).text\n",
    "        branch_dataset = Node(title, predecessor_node)\n",
    "        for child in branch.findall('nt:children', worldbank_namespaces):\n",
    "            branch_dataset.children = get_node_children(child, branch_dataset)\n",
    "        datasets.append(branch_dataset)\n",
    "\n",
    "    for leaf in root.findall('nt:leaf', worldbank_namespaces):\n",
    "        title = leaf.find('nt:title/[@language=\"en\"]', worldbank_namespaces).text\n",
    "        datasets.append(Leaf(title, predecessor_node))\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorldBank, #children: 3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldbank : Node = None\n",
    "if (os.path.exists(\"worldbank.pkl\")):\n",
    "    worldbank = pickle.load(open(\"worldbank.pkl\", \"rb\"))\n",
    "else:\n",
    "    worldbank = parse_worldbank_xml(\"worldBank_content.xml\")\n",
    "    pickle.dump(worldbank, open(\"worldbank.pkl\", \"wb\"))\n",
    "\n",
    "worldbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WebPage - HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "TIMEOUT = 10\n",
    "DEPTH = 2\n",
    "\n",
    "def parse_html_webpage(path : str) -> Node:\n",
    "    \"\"\"Parses the html webpage into a tree and returns the root node.\"\"\"\n",
    "    dataset = Node(\"MFF home page\", None, path)\n",
    "    dataset.add_children(get_html_children(dataset, DEPTH))\n",
    "    return dataset\n",
    "\n",
    "def get_html_children(predecessor_node : Node, remaining_depth : int) -> List['Node']:\n",
    "    \"\"\"Parses the given soup and returns the corresponding DataSet object.\"\"\"\n",
    "    datasets = []\n",
    "    if (remaining_depth <= 0): return datasets\n",
    "\n",
    "    print(f\"Requesting {predecessor_node.alternative_name}\")\n",
    "    page = requests.get(predecessor_node.alternative_name, timeout=TIMEOUT)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        if ('href' in link.attrs and link.text.strip() != '' and not url_is_blacklisted(link.attrs['href'])):\n",
    "            url = url_get_absolute(link.attrs['href'], predecessor_node.alternative_name)\n",
    "            title = re.sub('[\\\\n\\\\s]+',' ',link.text.strip())\n",
    "            branch_dataset = Node(title, predecessor_node, url)\n",
    "            branch_dataset.children = get_html_children(branch_dataset, remaining_depth - 1)\n",
    "            datasets.append(branch_dataset)\n",
    "    return datasets\n",
    "\n",
    "def url_is_blacklisted(url : str, base_url : str | None = None) -> bool:\n",
    "    \"\"\"Checks if the url is blacklisted. Blacklist is very basic.\"\"\"\n",
    "    ## keep relatives\n",
    "    if (url.startswith('./') or (url != \"/\" and url.startswith('/'))):\n",
    "        return False\n",
    "    \n",
    "    ## filter out some basic stuff\n",
    "    if (url == \"/\" \n",
    "        or url.startswith('#') \n",
    "        or url.startswith('mailto:') \n",
    "        or url.startswith('javascript:')\n",
    "        or url.startswith('tel:')\n",
    "        or (base_url is not None and not url.startswith(base_url))):\n",
    "        return True\n",
    "\n",
    "    ## passed\n",
    "    return False\n",
    "\n",
    "def url_get_absolute(input : str, current_url : str | None) -> str:\n",
    "        \"\"\"Tries to merge the relative input url with the current url prefix to get the absolute url. \n",
    "        If no current url is provided, the input is returned.\"\"\"\n",
    "        result = \"\"\n",
    "        \n",
    "        if (current_url is None): return input\n",
    "        ## remove the query string from the url\n",
    "        if ('?' in current_url): current_url = current_url.split('?')[0]\n",
    "        ## remove any anchors from the url\n",
    "        if ('#' in input): input = input.split('#')[0]\n",
    "\n",
    "        ## try to cut as much from the current url as possible\n",
    "        if (input.startswith('/')): \n",
    "            current_split = [x for x in current_url.split('/') if x != '']\n",
    "            input_split = [x for x in input.split('/') if x != '']\n",
    "            for i in range(len(current_split)):\n",
    "                if (len(input_split) == 0): return current_url\n",
    "                if (current_split[i] == input_split[0]): input_split.pop(0)\n",
    "            input = '/'.join(input_split)\n",
    "\n",
    "            if (current_url.endswith('/')): result = current_url + input\n",
    "            else: result = current_url + '/' + input\n",
    "        ## just append the relative to the current\n",
    "        elif (input.startswith('./')): result = current_url + input.strip('./')\n",
    "        ## otherwise legit URL given\n",
    "        else: result = input\n",
    "        ## always add the trailing slash if not present\n",
    "        if (not result.endswith('/') and not \".\" in result.split('/')[-1]): ## only except if file is given\n",
    "            result += '/'\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage : Node = None\n",
    "if (os.path.exists(\"webpage.pkl\")):\n",
    "    webpage = pickle.load(open(\"webpage.pkl\", \"rb\"))\n",
    "else:\n",
    "    webpage = parse_html_webpage(\"https://www.mff.cuni.cz/\")\n",
    "    pickle.dump(webpage, open(\"webpage.pkl\", \"wb\"))\n",
    "\n",
    "webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FileSystem - HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import deque\n",
    "\n",
    "def parse_html_file(path : str) -> Node:\n",
    "    \"\"\"Parses the html file into a tree and returns the root node.\"\"\"\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        return get_html_file_children(soup)\n",
    "    \n",
    "def get_html_file_children(soup : BeautifulSoup) -> Node:\n",
    "    stack = deque()\n",
    "    initial_node : Node = None\n",
    "    previous_node : Node = None\n",
    "    for link in soup.find_all('a'):\n",
    "        if ('href' in link.attrs and link.text.strip() != ''):\n",
    "            url : str = link.attrs['href']\n",
    "            dir : str = url[:url.rindex('/')]\n",
    "            file : str = url[url.rindex('/')+1:]\n",
    "            text : str = link.text.strip()\n",
    "\n",
    "            if (initial_node is None):\n",
    "                initial_node = Node(text, None, dir)\n",
    "                previous_node = initial_node\n",
    "                continue\n",
    "\n",
    "            if (file == \"\" and  dir.startswith(previous_node.alternative_name)): ## when the file is empty, it is a directory\n",
    "                current_node = Node(text, previous_node, dir)\n",
    "                previous_node.children.append(current_node)\n",
    "                stack.append(previous_node)\n",
    "                previous_node = current_node\n",
    "            elif (file != \"\" and dir.startswith(previous_node.alternative_name)): \n",
    "                previous_node.children.append(Leaf(file, previous_node, dir))\n",
    "            else:\n",
    "                while (len(stack) > 0 and not dir.startswith(previous_node.alternative_name)):\n",
    "                    previous_node = stack.pop()\n",
    "                if (file == \"\"): ## when the file is empty, it is a directory\n",
    "                    current_node = Node(text, previous_node, dir)\n",
    "                    previous_node.children.append(current_node)\n",
    "                    stack.append(previous_node)\n",
    "                    previous_node = current_node\n",
    "                elif (file != \"\" and dir.startswith(previous_node.alternative_name)): \n",
    "                    previous_node.children.append(Leaf(file, previous_node, dir))\n",
    "    return initial_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOCUMENTS, #children: 43"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesystem : Node = None\n",
    "if (os.path.exists(\"filesystem.pkl\")):\n",
    "    filesystem = pickle.load(open(\"filesystem.pkl\", \"rb\"))\n",
    "else:\n",
    "    filesystem = parse_html_file(\"filesystem_content.html\")\n",
    "    pickle.dump(filesystem, open(\"filesystem.pkl\", \"wb\"))\n",
    "\n",
    "filesystem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
