{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Prompt Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources and their cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node and Leaf definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name : str, predecessor : 'Node' = None, alternative_name : str = None):\n",
    "        self.name = name\n",
    "        self.predecessor = predecessor\n",
    "        self.alternative_name : str = alternative_name\n",
    "        self.children : List['Node'] = []\n",
    "\n",
    "    def get_child(self, index : int):\n",
    "        if (index >= len(self.children)):\n",
    "            assert IndexError\n",
    "        return self.children[index]\n",
    "    \n",
    "    def add_children(self, children : List['Node']):\n",
    "        for child in children:\n",
    "            child.predecessor = self\n",
    "            self.children.append(child)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name}, #children: {len(self.children)}\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "class Leaf(Node):\n",
    "    def __init__(self, name : str, predecessor : 'Node' = None, alternative_name : str = None):\n",
    "        super().__init__(name, predecessor, alternative_name)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name}\"\n",
    "    \n",
    "class CorrectPath:\n",
    "    def __init__(self, root : Node, query : str, child_sequences : List[List['int']]):\n",
    "        ## sequence must be given in reversed order, having the first move at the last position\n",
    "        self.root = root\n",
    "        self.query = query\n",
    "        self.child_sequences = child_sequences \n",
    "    \n",
    "    def is_next_move_correct(self, move_index : int) -> bool:\n",
    "        if (all(len(sequenece) == 0 for sequenece in self.child_sequences)): return False\n",
    "        if (any(move_index == sequence[-1] for sequence in self.child_sequences)): return True\n",
    "        else: return False\n",
    "        \n",
    "    def make_correct_step(self, move_index : int) -> Node | None:\n",
    "        if (all(len(sequenece) == 0 for sequenece in self.child_sequences)): return None\n",
    "        self.child_sequences = [sequence[:-1] for sequence in self.child_sequences if len(sequence) > 0 and sequence[-1] == move_index]\n",
    "        if (len(self.child_sequences) == 0): return None\n",
    "        self.root = self.root.get_child(self.child_sequences[0][-1])\n",
    "        return self.root\n",
    "    \n",
    "    def shortest_path_len(self) -> int:\n",
    "        return len(self.child_sequences)\n",
    "    \n",
    "    def is_at_the_end(self) -> bool:\n",
    "        return len(self.child_sequences) == 0\n",
    "\n",
    "def create_test_sequence(root : Node, query : str, child_sequences_str : List['str']) -> 'CorrectPath':\n",
    "    child_sequences = [[int(x) for x in child_sequence_str.split().__reversed__()] for child_sequence_str in child_sequences_str]\n",
    "    return CorrectPath(root, query, child_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WorldBank - XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "worldbank_namespaces =  {\n",
    "        'nt': 'urn:eu.europa.ec.eurostat.navtree'\n",
    "    }\n",
    "\n",
    "def parse_worldbank_xml(path : str) -> Node:\n",
    "    \"\"\"Parses the xml tree from the given path and returns the root node.\"\"\"\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    dataset : Node = Node(\"WorldBank\")\n",
    "    dataset.add_children(get_node_children(root, dataset))\n",
    "    return dataset\n",
    "\n",
    "def get_node_children(root : ET.Element, predecessor_node : Node) -> List['Node']:\n",
    "    \"\"\"Parses the given root node and returns the corresponding DataSet object.\"\"\"\n",
    "    datasets = []\n",
    "    for branch in root.findall('nt:branch', worldbank_namespaces):\n",
    "        title = branch.find('nt:title/[@language=\"en\"]', worldbank_namespaces).text\n",
    "        branch_dataset = Node(title, predecessor_node)\n",
    "        for child in branch.findall('nt:children', worldbank_namespaces):\n",
    "            branch_dataset.children = get_node_children(child, branch_dataset)\n",
    "        datasets.append(branch_dataset)\n",
    "\n",
    "    for leaf in root.findall('nt:leaf', worldbank_namespaces):\n",
    "        title = leaf.find('nt:title/[@language=\"en\"]', worldbank_namespaces).text\n",
    "        datasets.append(Leaf(title, predecessor_node))\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorldBank, #children: 3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldbank : Node = None\n",
    "if (os.path.exists(\"worldbank.pkl\")):\n",
    "    worldbank = pickle.load(open(\"worldbank.pkl\", \"rb\"))\n",
    "else:\n",
    "    worldbank = parse_worldbank_xml(\"worldBank_content.xml\")\n",
    "    pickle.dump(worldbank, open(\"worldbank.pkl\", \"wb\"))\n",
    "\n",
    "worldbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WebPage - HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from bs4 import BeautifulSoup\n",
    "from copy import deepcopy\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "SLEEP_TIME = 5\n",
    "TIMEOUT = 10\n",
    "DEPTH = 8\n",
    "ATTEMPTS_COUNT = 3\n",
    "\n",
    "def parse_html_webpage(path : str) -> Node:\n",
    "    \"\"\"Parses the html webpage into a tree and returns the root node.\"\"\"\n",
    "    dataset = Node(\"MFF home page\", None, path)\n",
    "    dataset.add_children(get_html_children(dataset, DEPTH))\n",
    "    return dataset\n",
    "\n",
    "def get_html_children(predecessor_node : Node, remaining_depth : int, cache : Dict[tuple[str, int], Node] = {}) -> List['Node']:\n",
    "    \"\"\"Parses the given soup and returns the corresponding DataSet object.\"\"\"\n",
    "    \"\"\"If item found in the cachce, it will be returned from there. Key of the cache is the url and the remaining depth.\"\"\"\n",
    "    \"\"\"I can always cut the depth of the children to the required level, but I cannot expand the children if the depth is not enough.\"\"\"\n",
    "    child_webpages = []\n",
    "    if (remaining_depth <= 0): return child_webpages\n",
    "\n",
    "    attempt_count = 1\n",
    "    page : requests.Response = None\n",
    "    soup : BeautifulSoup = None\n",
    "    while (attempt_count <= ATTEMPTS_COUNT):\n",
    "        try:\n",
    "            time.sleep(SLEEP_TIME)\n",
    "            page = requests.get(predecessor_node.alternative_name, timeout=TIMEOUT)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt_count} failed. Error: {e}\")\n",
    "        finally:\n",
    "            attempt_count += 1\n",
    "    \n",
    "    if (page == None): return child_webpages\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        if ('href' in link.attrs and link.text.strip() != '' and not url_is_blacklisted(link.attrs['href'])):\n",
    "            url = url_get_absolute(link.attrs['href'], predecessor_node.alternative_name)\n",
    "            ## check if any key with same or higher depth_remaining is in the cache\n",
    "            key : tuple[str,int] = (url, next((x for x in range(remaining_depth-1, DEPTH, 1) if (url, x) in cache), None))\n",
    "            if (key[1] is not None): ## if anything found in the cache\n",
    "                branch_dataset = deepcopy(cache[key]) ## copy the cached item\n",
    "                cut_children_depth(branch_dataset, remaining_depth-1) ## cut the depth to the required level\n",
    "                branch_dataset.predecessor = predecessor_node ## set the predecessor\n",
    "                branch_dataset.alternative_name = url ## set the alternative name to its url\n",
    "            else:\n",
    "                title = re.sub('[\\\\n\\\\s]+',' ',link.text.strip())\n",
    "                branch_dataset = Node(title, predecessor_node, url) ## create new item\n",
    "                branch_dataset.add_children(get_html_children(branch_dataset, remaining_depth - 1, cache)) ## expand the children\n",
    "                ## remove all chached items with same url and lower depth\n",
    "                if (any(k[0] == url and k[1] < remaining_depth for k in cache.keys())):\n",
    "                    cache = {k:v for k,v in cache.items() if k[0] != url or k[1] > remaining_depth}\n",
    "                cache[(url, remaining_depth-1)] = branch_dataset\n",
    "            child_webpages.append(branch_dataset) ## add to the children response\n",
    "    return child_webpages\n",
    "\n",
    "def url_is_blacklisted(url : str, base_url : str | None = None) -> bool:\n",
    "    \"\"\"Checks if the url is blacklisted. Blacklist is very basic.\"\"\"\n",
    "    ## keep relatives\n",
    "    if (url.startswith('./') or (url != \"/\" and url.startswith('/'))):\n",
    "        return False\n",
    "    \n",
    "    ## filter out some basic stuff\n",
    "    if (url == \"/\" \n",
    "        or url.startswith('#') \n",
    "        or url.startswith('mailto:') \n",
    "        or url.startswith('javascript:')\n",
    "        or url.startswith('tel:')\n",
    "        or (base_url is not None and not url.startswith(base_url))):\n",
    "        return True\n",
    "\n",
    "    ## passed\n",
    "    return False\n",
    "\n",
    "def url_get_absolute(input : str, current_url : str | None) -> str:\n",
    "        \"\"\"Tries to merge the relative input url with the current url prefix to get the absolute url. \n",
    "        If no current url is provided, the input is returned.\"\"\"\n",
    "        result = \"\"\n",
    "        \n",
    "        if (current_url is None): return input\n",
    "        ## remove the query string from the url\n",
    "        if ('?' in current_url): current_url = current_url.split('?')[0]\n",
    "        ## remove any anchors from the url\n",
    "        if ('#' in input): input = input.split('#')[0]\n",
    "\n",
    "        ## try to cut as much from the current url as possible\n",
    "        if (input.startswith('/')): \n",
    "            current_split = [x for x in current_url.split('/') if x != '']\n",
    "            input_split = [x for x in input.split('/') if x != '']\n",
    "            for i in range(len(current_split)):\n",
    "                if (len(input_split) == 0): return current_url\n",
    "                if (current_split[i] == input_split[0]): input_split.pop(0)\n",
    "            input = '/'.join(input_split)\n",
    "\n",
    "            if (current_url.endswith('/')): result = current_url + input\n",
    "            else: result = current_url + '/' + input\n",
    "        ## just append the relative to the current\n",
    "        elif (input.startswith('./')): result = current_url + input.strip('./')\n",
    "        ## otherwise legit URL given\n",
    "        else: result = input\n",
    "        ## always add the trailing slash if not present\n",
    "        if (not result.endswith('/') and not \".\" in result.split('/')[-1]): ## only except if file is given\n",
    "            result += '/'\n",
    "\n",
    "        return result\n",
    "\n",
    "def cut_children_depth(node : Node, depth : int):\n",
    "    \"\"\"Cuts the tree depth to the given depth.\"\"\"\n",
    "    if (depth <= 0):\n",
    "        node.children = []\n",
    "        return\n",
    "    for child in node.children:\n",
    "        cut_children_depth(child, depth - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webpage : Node = None\n",
    "# if (os.path.exists(\"webpage.pkl\")):\n",
    "#     webpage = pickle.load(open(\"webpage.pkl\", \"rb\"))\n",
    "# else:\n",
    "#     webpage = parse_html_webpage(\"https://www.mff.cuni.cz/\")\n",
    "#     pickle.dump(webpage, open(\"webpage.pkl\", \"wb\"))\n",
    "\n",
    "# webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FileSystem - HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import deque\n",
    "\n",
    "def parse_html_file(path : str) -> Node:\n",
    "    \"\"\"Parses the html file into a tree and returns the root node.\"\"\"\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        return get_html_file_children(soup)\n",
    "    \n",
    "def get_html_file_children(soup : BeautifulSoup) -> Node:\n",
    "    stack = deque()\n",
    "    initial_node : Node = None\n",
    "    previous_node : Node = None\n",
    "    for link in soup.find_all('a'):\n",
    "        if ('href' in link.attrs and link.text.strip() != ''):\n",
    "            url : str = link.attrs['href']\n",
    "            dir : str = url[:url.rindex('/')]\n",
    "            file : str = url[url.rindex('/')+1:]\n",
    "            text : str = link.text.strip()\n",
    "\n",
    "            if (initial_node is None):\n",
    "                initial_node = Node(text, None, dir)\n",
    "                previous_node = initial_node\n",
    "                continue\n",
    "\n",
    "            if (file == \"\" and  dir.startswith(previous_node.alternative_name)): ## when the file is empty, it is a directory\n",
    "                current_node = Node(text, previous_node, dir)\n",
    "                previous_node.children.append(current_node)\n",
    "                stack.append(previous_node)\n",
    "                previous_node = current_node\n",
    "            elif (file != \"\" and dir.startswith(previous_node.alternative_name)): \n",
    "                previous_node.children.append(Leaf(file, previous_node, dir))\n",
    "            else:\n",
    "                while (len(stack) > 0 and not dir.startswith(previous_node.alternative_name)):\n",
    "                    previous_node = stack.pop()\n",
    "                if (file == \"\"): ## when the file is empty, it is a directory\n",
    "                    current_node = Node(text, previous_node, dir)\n",
    "                    previous_node.children.append(current_node)\n",
    "                    stack.append(previous_node)\n",
    "                    previous_node = current_node\n",
    "                elif (file != \"\" and dir.startswith(previous_node.alternative_name)): \n",
    "                    previous_node.children.append(Leaf(file, previous_node, dir))\n",
    "    return initial_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOCUMENTS, #children: 43"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesystem : Node = None\n",
    "if (os.path.exists(\"filesystem.pkl\")):\n",
    "    filesystem = pickle.load(open(\"filesystem.pkl\", \"rb\"))\n",
    "else:\n",
    "    filesystem = parse_html_file(\"filesystem_content.html\")\n",
    "    pickle.dump(filesystem, open(\"filesystem.pkl\", \"wb\"))\n",
    "\n",
    "filesystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Assistant - ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from openAI_secret import API_KEY\n",
    "from consts import MODEL\n",
    "\n",
    "class OpenAIWrapper:\n",
    "    def __init__(self, keep_whole_context : bool, system_message : str):\n",
    "        self.client = OpenAI(api_key=API_KEY)\n",
    "        self.keep_whole_context = keep_whole_context\n",
    "        self.system_message = system_message\n",
    "        self.messages = [self.__create_system_message(self.system_message)]\n",
    "\n",
    "    def __create_user_message(self, content):\n",
    "        return {\"role\": \"user\", \"content\": content}\n",
    "    \n",
    "    def __create_system_message(self, content):\n",
    "        return {\"role\": \"system\", \"content\": content}\n",
    "    \n",
    "    def __create_assistant_message(self, content):\n",
    "        return {\"role\": \"assistant\", \"content\": content}\n",
    "    \n",
    "    def __add_message(self, content):\n",
    "        if (self.keep_whole_context):\n",
    "            self.messages.append(self.__create_user_message(content))\n",
    "        else:\n",
    "            self.messages = [\n",
    "                self.__create_system_message(self.system_message),\n",
    "                self.__create_user_message(content) \n",
    "            ]\n",
    "\n",
    "    def __get_response(self):\n",
    "        full_response = self.client.chat.completions.create(\n",
    "            model = MODEL,\n",
    "            messages=self.messages,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        response_content = full_response.choices[-1].message.content\n",
    "        self.messages.append(self.__create_assistant_message(response_content))\n",
    "        return response_content\n",
    "    \n",
    "    def get_response_to_prompt(self, prompt) -> str:\n",
    "        self.__add_message(prompt)\n",
    "        response = self.__get_response()\n",
    "        return response if response is not None else \"\"\n",
    "    \n",
    "    def get_additional_response(self, prompt) -> str:\n",
    "        self.messages.append(self.__create_user_message(prompt))\n",
    "        return self.__get_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from consts import *\n",
    "\n",
    "class AssistantWorker:\n",
    "    def __init__(self, look_ahead_depth : int = 1):\n",
    "        self.stemmer : SnowballStemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "        self.look_ahead_depth = look_ahead_depth\n",
    "        pass\n",
    "\n",
    "    def create_llm_query(self, initial_query : str, path_done : List['Node'], current_node : Node, mode : int) -> str:\n",
    "        \"\"\"Creates a query for the LLM model based on the current node.\"\"\"\n",
    "        next_moves = []\n",
    "        prompt = \"\"\n",
    "        steps_so_far = \" -> \".join([node.name for node in path_done])\n",
    "\n",
    "        match mode:\n",
    "            case WORKER_MODE.STEP_BY_STEP | WORKER_MODE.MATCH_AND_FILTER:\n",
    "                next_moves = [f\"\\t{i}: {child.name}\\n\" for i, child in enumerate(current_node.children)]\n",
    "                prompt = (\n",
    "                f\"query: {initial_query}\\n\"\n",
    "                f\"steps done: {steps_so_far}\\n\"\n",
    "                f\"next possible subsection names:\\n\"\n",
    "                f\"{''.join(next_moves)}\"\n",
    "                )\n",
    "            case WORKER_MODE.LOOK_AHEAD:\n",
    "                for i, child in enumerate(current_node.children):\n",
    "                    next_moves.append(f\"{i}: {self.create_look_ahead_prompt(child, self.look_ahead_depth-1, self.look_ahead_depth-1)}\")\n",
    "                prompt = (\n",
    "                f\"query: {initial_query}\\n\"\n",
    "                f\"steps done: {steps_so_far}\\n\"\n",
    "                f\"next possible subsection names:\\n\"\n",
    "                f\"{''.join(next_moves)}\"\n",
    "                )\n",
    "            case WORKER_MODE.KEYWORD_GEN_AND_MATCH:\n",
    "                prompt = (\n",
    "                f\"query: {initial_query}\\n\"\n",
    "                f\"For the query above, please write {NUM_OF_KEYWORDS} keywords that might be relevant names of subsections to dive into in an upcoming search. Prefere single words. Use the language of the query!\\n\"\n",
    "                f\"Please separate the keywords with semicolon. Dont write anything else!\\n\"\n",
    "                )\n",
    "\n",
    "        return prompt\n",
    "    \n",
    "    def create_llm_nonint_message() -> str:\n",
    "        response = f\"You must only return integer, for example 3. If you don't know the answer, return -1\"\n",
    "        return response\n",
    "    \n",
    "    def create_llm_wrong_answer_message() -> str:\n",
    "        response = f\"Your answer was not valid. Please try again.\"\n",
    "        return response\n",
    "\n",
    "    def process_llm_child_pick_response(self, raw_response : str) -> int | None:\n",
    "        \"\"\"Returns the child index of the llm decision. Returns -1 if doesn't, returns NONE if non-digit answer given.\"\"\"\n",
    "        response = raw_response.strip()\n",
    "\n",
    "        if (response == \"-1\"):\n",
    "            return -1\n",
    "        \n",
    "        if not response.isdigit():\n",
    "            print(f\"Response is not digit, raw response: {raw_response}\")\n",
    "            return None\n",
    "        else:\n",
    "            try:\n",
    "                int_response = int(response)\n",
    "                return int_response\n",
    "            except:\n",
    "                print(f\"Invalid response, raw response: {raw_response}\")\n",
    "                return None\n",
    "\n",
    "    def process_llm_keyword_gen_response(self, raw_response : str) -> List['str']:\n",
    "        return [self.stemmer.stem(x.strip().casefold()) for x in raw_response.split(\";\")]\n",
    "    \n",
    "    def create_look_ahead_prompt(self, child : Node, depth_total : int, depth_remaining : int):\n",
    "        tab = '\\t'\n",
    "        newline = '\\n'\n",
    "        prompt = f\"{''.join([tab for _ in range(depth_total - depth_remaining)])}: {child.name}{newline}\"\n",
    "        \n",
    "        if depth_remaining == 0:\n",
    "            return prompt\n",
    "        \n",
    "        for i, grandchild in enumerate(child.children):\n",
    "            prompt += f\"{self.create_look_ahead_prompt(grandchild, depth_total, depth_remaining - 1)}\"\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions of text executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "REPETITION_COUNT = 2\n",
    "MAX_NUM_OF_TRIES = 5\n",
    "\n",
    "class TestResult:\n",
    "    def __init__(self, shortest_path : int):\n",
    "        self.shortest_path = shortest_path\n",
    "        self.steps_taken = 0\n",
    "        self.wrong_moves = 0\n",
    "        self.sucess = False\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"Correct: {self.sucess}, steps: {self.steps_taken}, wrong: {self.wrong_moves}\"\n",
    "    \n",
    "    def __repr__(self) -> str: return self.__str__()\n",
    "\n",
    "class TestRunner:\n",
    "    def execute(self, tests : List['CorrectPath'], openai : OpenAIWrapper, worker : AssistantWorker, mode : int):\n",
    "        for _ in range(REPETITION_COUNT):\n",
    "            for test in tests:\n",
    "                result = self.__run(test.root, test.query, worker, openai, test, mode)\n",
    "                print(f\"Test result: {result}\")\n",
    "\n",
    "    def __run(self, root : Node, query : str, worker : AssistantWorker, openai : OpenAIWrapper, correct_path : CorrectPath, mode : int) -> TestResult:\n",
    "        path_done : List['Node'] = []\n",
    "        current_node = root\n",
    "        result : TestResult = TestResult(correct_path.shortest_path_len())\n",
    "        while (True):\n",
    "            prompt = worker.create_llm_query(query, path_done, current_node, mode)\n",
    "            print(f\"Prompt: {prompt}\")\n",
    "            next_child_index = worker.process_llm_child_pick_response(openai.get_response_to_prompt(prompt))\n",
    "            print(f\"Response: {next_child_index}\")\n",
    "            result.steps_taken += 1\n",
    "            if (next_child_index is None):\n",
    "                result.wrong_moves += 1\n",
    "                additional_prompt = worker.create_llm_nonint_message()\n",
    "                print(f\"\\tAdditional prompt: {additional_prompt}\")\n",
    "                next_child_index = worker.process_llm_child_pick_response(openai.get_additional_response(additional_prompt))\n",
    "                print(f\"\\tAdditional response: {next_child_index}\")\n",
    "                result.steps_taken += 1\n",
    "                if (next_child_index is None):\n",
    "                    result.wrong_moves += 1\n",
    "                    result.sucess = False\n",
    "                    break\n",
    "                else:\n",
    "                    should_break, next_child_index = self.__process_valid_response(next_child_index, result, worker, openai, correct_path, path_done)\n",
    "                    if (should_break): break\n",
    "            else:\n",
    "                should_break, next_child_index = self.__process_valid_response(next_child_index, result, worker, openai, correct_path, path_done)\n",
    "                if (should_break): break\n",
    "            ## continue to the next node\n",
    "            path_done.append(current_node)\n",
    "            current_node = correct_path.make_correct_step(next_child_index)\n",
    "        return result\n",
    "    \n",
    "    def __process_valid_response(self, next_child_index : int, result : TestResult, worker : AssistantWorker, openai : OpenAIWrapper, correct_path : CorrectPath, path_done : List['Node']) -> tuple[bool, int]:\n",
    "        if (correct_path.is_at_the_end()): ## when already at the end\n",
    "            if (next_child_index == -1): ## if the assistant knows it is the end\n",
    "                result.sucess = True\n",
    "                return (True, -1)\n",
    "            else: ## if the assistant doesn't know it is the end\n",
    "                result.sucess = False\n",
    "                return (True, -1)\n",
    "        else:\n",
    "            num_of_tries = 1\n",
    "            while (not correct_path.is_next_move_correct(next_child_index) and num_of_tries <= MAX_NUM_OF_TRIES):\n",
    "                result.wrong_moves += 1\n",
    "                wrong_response_prompt = worker.create_llm_wrong_answer_message()\n",
    "                next_child_index = worker.process_llm_child_pick_response(openai.get_response_to_prompt(wrong_response_prompt))\n",
    "                result.steps_taken += 1\n",
    "                if (next_child_index is None):\n",
    "                    result.wrong_moves += 1\n",
    "                    additional_prompt = worker.create_llm_nonint_message()\n",
    "                    next_child_index = worker.process_llm_child_pick_response(openai.get_additional_response(additional_prompt))\n",
    "                    result.steps_taken += 1\n",
    "                    if (next_child_index is None):\n",
    "                        result.wrong_moves += 1\n",
    "                        result.sucess = False\n",
    "                        return (True, -1)\n",
    "                num_of_tries += 1\n",
    "\n",
    "            if (correct_path.is_next_move_correct(next_child_index)):\n",
    "                return (False, next_child_index)\n",
    "            else:\n",
    "                result.sucess = False\n",
    "                return (True, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Worldbank - Step by step\n",
    "Every test contains a source, a user (human friendly) query to which should be the relevant database table found and a list of sequences of indexes (zero based) that lead to the correct table.\n",
    "\n",
    "The table of content of whole eurostat database was gathered at February 2024 and is saved locally.\n",
    "\n",
    "When deciding, whether the current path is of the assistant is correct, any matching correct sequence will satisfy. All other sequences that are not following the same path are removed at the first node with a mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_worldbank_step_by_step = [\n",
    "    create_test_sequence(worldbank, \"What was the GDP growth rate for Czech Republic in 2019?\", [\n",
    "        \"0 1 0 0 0 0\"]),\n",
    "    create_test_sequence(worldbank, \"How many people lived in Germany in 2020?\", [\n",
    "        \"0 2 1 1 0\", \"0 2 1 1 1\", \"0 2 1 1 2\", \n",
    "        \"0 2 1 1 3\", \"0 2 1 1 4\", \"0 2 1 1 5\", \n",
    "        \"0 2 1 1 6\", \"0 2 1 1 7\", \"0 2 1 1 8\", \n",
    "        \"0 2 1 1 9\", \"0 2 1 1 10\", \"0 2 1 1 11\", \n",
    "        \"0 2 1 1 12\"]),\n",
    "    create_test_sequence(worldbank, \"What was the unemployment rate in Austria in 2015?\", [\n",
    "        \"1 2 5 0 0 2 0\", \"1 2 5 0 0 2 1\", \"1 2 5 0 0 2 2\"]),\n",
    "    create_test_sequence(worldbank, \"What percentage of the population in Europe had access to clean water and sanitation facilities in 2010\", [\n",
    "        \"2 3 5 0\"]),\n",
    "    create_test_sequence(worldbank, \"What was the government expenditure on healthcare per capita in Poland in 2018\", [\"\"]),\n",
    "    create_test_sequence(worldbank, \"How much renewable energy was consumed as a percentage of total energy consumption in Great Britain in 2020\", [\"\"]),\n",
    "    create_test_sequence(worldbank, \"What was the carbon emissions level for Ukraine in 2014\", [\"\"]),\n",
    "    create_test_sequence(worldbank, \"What was the inflation rate in Italy in 2018\", [\"\"]),\n",
    "    create_test_sequence(worldbank, \"What was the total external debt of Czech Republic in 2021, and how does it compare to its GDP\", [\"\"]),\n",
    "    create_test_sequence(worldbank, \"What percentage of the population in India had access to electricity in 2010\", [\"\"]),\n",
    "    create_test_sequence(worldbank, \"What was the total value of exports and imports for Germany in 2020, and what was the trade balance?\", [\"\"]),\n",
    "    create_test_sequence(worldbank, \"What was the ratio of female to male participation in the labor force in Romania in 2015\", [\"\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: query: How many people lived in Germany in 2020?\n",
      "steps done: \n",
      "next possible subsection names:\n",
      "\t0: Database by themes\n",
      "\t1: Tables on EU policy\n",
      "\t2: Cross cutting topics\n",
      "\n",
      "Response: 0\n",
      "Prompt: query: How many people lived in Germany in 2020?\n",
      "steps done: WorldBank\n",
      "next possible subsection names:\n",
      "\t0: Quality of life\n",
      "\t1: Migrant integration and children in migration\n",
      "\t2: Economic globalisation indicators\n",
      "\t3: Equality (age and gender)\n",
      "\t4: Quality of employment\n",
      "\t5: Agri-environmental indicators\n",
      "\t6: Climate change\n",
      "\t7: Skills-related statistics\n",
      "\t8: Youth\n",
      "\n",
      "Response: -1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AssistantWorker.create_llm_wrong_answer_message() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m worker \u001b[38;5;241m=\u001b[39m AssistantWorker()\n\u001b[0;32m      8\u001b[0m runner \u001b[38;5;241m=\u001b[39m TestRunner()\n\u001b[1;32m----> 9\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtests_worldbank_step_by_step\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWORKER_MODE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTEP_BY_STEP\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[80], line 22\u001b[0m, in \u001b[0;36mTestRunner.execute\u001b[1;34m(self, tests, openai, worker, mode)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(REPETITION_COUNT):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m tests:\n\u001b[1;32m---> 22\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[80], line 50\u001b[0m, in \u001b[0;36mTestRunner.__run\u001b[1;34m(self, root, query, worker, openai, correct_path, mode)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (should_break): \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     should_break, next_child_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__process_valid_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_child_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrect_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_done\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (should_break): \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m## continue to the next node\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[80], line 69\u001b[0m, in \u001b[0;36mTestRunner.__process_valid_response\u001b[1;34m(self, next_child_index, result, worker, openai, correct_path, path_done)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m correct_path\u001b[38;5;241m.\u001b[39mis_next_move_correct(next_child_index) \u001b[38;5;129;01mand\u001b[39;00m num_of_tries \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m MAX_NUM_OF_TRIES):\n\u001b[0;32m     68\u001b[0m     result\u001b[38;5;241m.\u001b[39mwrong_moves \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 69\u001b[0m     wrong_response_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_llm_wrong_answer_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     next_child_index \u001b[38;5;241m=\u001b[39m worker\u001b[38;5;241m.\u001b[39mprocess_llm_child_pick_response(openai\u001b[38;5;241m.\u001b[39mget_response_to_prompt(wrong_response_prompt))\n\u001b[0;32m     71\u001b[0m     result\u001b[38;5;241m.\u001b[39msteps_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: AssistantWorker.create_llm_wrong_answer_message() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "\n",
    "system_message = \"You are an assistant that is helping a user to navigate through the World Bank data.\\\n",
    "    You are given a query and all available subsections.\\\n",
    "    You should help the user to navigate to the correct subsection.\\\n",
    "    Answer only with the number of the subsection.\\\n",
    "    If you don't know the answer, return -1.\"\n",
    "openai = OpenAIWrapper(False, system_message)\n",
    "worker = AssistantWorker()\n",
    "runner = TestRunner()\n",
    "runner.execute([tests_worldbank_step_by_step[1]], openai, worker, WORKER_MODE.STEP_BY_STEP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
